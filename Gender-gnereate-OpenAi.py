import os
import re
import time
import json
import random
import requests
import pandas as pd
from google.colab import drive, userdata

# ==============================
# Ø¥Ø¹Ø¯Ø§Ø¯ Google Drive
# ==============================
drive.mount('/content/drive')

# ==============================
# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª OpenAI Batch API
# ==============================
OPENAI_FILES_URL = "https://api.openai.com/v1/files"
OPENAI_BATCHES_URL = "https://api.openai.com/v1/batches"
OPENAI_CHAT_ENDPOINT = "/v1/chat/completions"
MODEL = "gpt-4o-mini"
BATCH_COMPLETION_WINDOW = "24h"

# ==============================
# Ø§Ù„Ù…ÙØªØ§Ø­
# ==============================
API_KEY = ""
try:
    API_KEY = userdata.get('Mohanad') or userdata.get('OPENAI_API_KEY') or ""
except Exception:
    pass
if not API_KEY:
    API_KEY = os.environ.get('Mohanad', '') or os.environ.get('OPENAI_API_KEY', '')
if not API_KEY:
    raise SystemExit("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…ÙØªØ§Ø­ OpenAI (Mohanad / OPENAI_API_KEY)")

# ==============================
# Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª
# ==============================
INPUT_XLSX = "/content/drive/MyDrive/Tweet_Project/Data/Gender_dallah.xlsx"
REQ_JSONL  = "/content/drive/MyDrive/Tweet_Project/Data/gender_requests.jsonl"
MAP_JSONL  = "/content/drive/MyDrive/Tweet_Project/Data/gender_mapping.jsonl"
RAW_OUT    = "/content/drive/MyDrive/Tweet_Project/Data/gender_batch_output.jsonl"
OUT_XLSX   = "/content/drive/MyDrive/Tweet_Project/Data/Gender_dallah_with_genders.xlsx"

# ==============================
# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ù…Ù† Ø§Ù„Ø³Ø·Ø± 2150 Ø¥Ù„Ù‰ 3000)
# ==============================
def load_rows_2150_to_3000(path):
    df = pd.read_excel(path)
    # ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø© Ù„Ù„Ø£Ø¹Ù…Ø¯Ø©
    cols = {c.strip().lower(): c for c in df.columns}
    def pick(*cands):
        for c in cands:
            if c in cols: return cols[c]
        return None

    col_name  = pick("author.name", "name", "author name", "author_name")
    col_user  = pick("author.username", "username", "user", "screen_name", "author_username")
    col_desc  = pick("author.description", "description", "bio", "author_description")

    if not (col_name and col_user and col_desc):
        raise ValueError(f"Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©. Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©: {list(df.columns)}")

    # Ø£Ø®Ø° Ø§Ù„Ø£Ø³Ø·Ø± Ù…Ù† 2149 (index) Ø¥Ù„Ù‰ 2999 (index) - Ø£ÙŠ Ù…Ù† Ø§Ù„Ø³Ø·Ø± 2150 Ø¥Ù„Ù‰ 3000
    df = df[[col_name, col_user, col_desc]].iloc[4000:6000].copy()
    df.columns = ["author.name", "author.username", "author.description"]
    # Ù…Ù„Ø¡ ÙØ±Ø§ØºØ§Øª
    for c in df.columns:
        df[c] = df[c].astype(str).fillna("").replace("nan", "", regex=False)

    print(f"ğŸ“Š ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(df)} Ø³Ø·Ø± (Ù…Ù† Ø§Ù„Ø³Ø·Ø± 2150 Ø¥Ù„Ù‰ {2149 + len(df)})")
    return df

# ==============================
# Ø¨Ù†Ø§Ø¡ Ø±Ø³Ø§Ù„Ø© Ø§Ù„ØªØµÙ†ÙŠÙ
# ==============================
def j(s):  # JSON-safe
    return json.dumps("" if s is None else str(s), ensure_ascii=False)

SYSTEM_PROMPT = (
    "You are a cautious classifier. Task: infer the account holder's *perceived* gender "
    "purely from provided fields (display name, username, description). "
    "Output one of: male, female, unknown.\n\n"
    "Rules:\n"
    "- If organization/brand/media/news/job board, or multiple people, return unknown.\n"
    "- If evidence is insufficient/ambiguous, return unknown.\n"
    "- Prefer not to guess. Only use clear linguistic/onomastic cues (Arabic/English names, pronouns, emojis).\n"
    "- Do not add explanations; return JSON only."
)

def build_user_message(row):
    name = j(row["author.name"])
    user = j(row["author.username"])
    desc = j(row["author.description"])

    # ØªØ¹Ù„ÙŠÙ…Ø§Øª ØµØ§Ø±Ù…Ø© Ù„Ø¥Ø®Ø±Ø§Ø¬ JSON ÙÙ‚Ø·
    msg = (
        "Classify perceived gender for this X/Twitter account.\n"
        f"display_name: {name}\n"
        f"username: {user}\n"
        f"description: {desc}\n\n"
        "Return ONLY valid JSON object exactly like: {\"gender\":\"male|female|unknown\"}"
    )
    return msg

# ==============================
# Ø¥Ø¹Ø¯Ø§Ø¯ JSONL + Mapping
# ==============================
def prepare_jsonl_for_batch(df, req_path, map_path):
    with open(req_path, "w", encoding="utf-8") as jf, open(map_path, "w", encoding="utf-8") as mf:
        ts = int(time.time() * 1000)
        for i, row in df.reset_index(drop=True).iterrows():
            custom_id = f"gender-2150-3000-{ts}-{i+1}"
            user_msg = build_user_message(row)
            body = {
                "custom_id": custom_id,
                "method": "POST",
                "url": OPENAI_CHAT_ENDPOINT,
                "body": {
                    "model": MODEL,
                    "messages": [
                        {"role": "system", "content": SYSTEM_PROMPT},
                        {"role": "user",   "content": user_msg}
                    ],
                    "response_format": {"type": "json_object"},
                    "temperature": 0.0,
                    "max_tokens": 20
                }
            }
            jf.write(json.dumps(body, ensure_ascii=False) + "\n")
            mf.write(json.dumps({
                "custom_id": custom_id,
                "row_index": int(i),
                "original_row": int(i + 2150),  # Ø¥Ø¶Ø§ÙØ© Ø±Ù‚Ù… Ø§Ù„Ø³Ø·Ø± Ø§Ù„Ø£ØµÙ„ÙŠ
                "name": row["author.name"],
                "username": row["author.username"],
                "description": row["author.description"]
            }, ensure_ascii=False) + "\n")
    print(f"ğŸ—‚ï¸ JSONL Ø§Ù„Ø·Ù„Ø¨Ø§Øª: {req_path}")
    print(f"ğŸ—ºï¸ JSONL Ø§Ù„Ù…Ø§Ø¨Ù†Ø¬: {map_path}")

# ==============================
# ÙˆØ¸Ø§Ø¦Ù Batch API
# ==============================
def upload_file_for_batch(jsonl_path: str) -> str:
    headers = {"Authorization": f"Bearer {API_KEY}"}
    files = {"file": (os.path.basename(jsonl_path), open(jsonl_path, 'rb'))}
    data = {"purpose": "batch"}
    r = requests.post(OPENAI_FILES_URL, headers=headers, files=files, data=data, timeout=180)
    if r.status_code != 200:
        raise RuntimeError(f"File upload failed: {r.status_code} {r.text}")
    fid = r.json()["id"]
    print(f"ğŸ“ ØªÙ… Ø§Ù„Ø±ÙØ¹: file_id={fid}")
    return fid

def create_batch_job(file_id: str, completion_window: str = BATCH_COMPLETION_WINDOW) -> str:
    headers = {"Authorization": f"Bearer {API_KEY}", "Content-Type": "application/json"}
    payload = {"input_file_id": file_id, "endpoint": OPENAI_CHAT_ENDPOINT, "completion_window": completion_window}
    r = requests.post(OPENAI_BATCHES_URL, headers=headers, json=payload, timeout=60)
    if r.status_code != 200:
        raise RuntimeError(f"Create batch failed: {r.status_code} {r.text}")
    bid = r.json()["id"]
    print(f"ğŸ“¦ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Batch: batch_id={bid}")
    return bid

def poll_batch_until_done(batch_id: str, poll_interval: int = 20) -> dict:
    headers = {"Authorization": f"Bearer {API_KEY}"}
    while True:
        r = requests.get(f"{OPENAI_BATCHES_URL}/{batch_id}", headers=headers, timeout=60)
        if r.status_code != 200:
            raise RuntimeError(f"Batch status failed: {r.status_code} {r.text}")
        obj = r.json()
        status = obj.get("status")
        print(f"â³ Ø­Ø§Ù„Ø© Ø§Ù„Ø¨Ø§ØªØ´: {status}")
        if status in ("completed", "failed", "canceled"):
            return obj
        time.sleep(poll_interval)

def download_file_content(file_id: str) -> str:
    headers = {"Authorization": f"Bearer {API_KEY}"}
    r = requests.get(f"{OPENAI_FILES_URL}/{file_id}/content", headers=headers, timeout=180)
    if r.status_code != 200:
        raise RuntimeError(f"Download file failed: {r.status_code} {r.text}")
    return r.text

# ==============================
# Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ø§Ø¨Ù†Ø¬
# ==============================
def load_mapping(map_path: str) -> dict:
    mapping = {}
    with open(map_path, "r", encoding="utf-8") as f:
        for line in f:
            if not line.strip():
                continue
            row = json.loads(line)
            mapping[row["custom_id"]] = row
    return mapping

# ==============================
# ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ ÙˆØ¯Ù…Ø¬Ù‡
# ==============================
def parse_and_merge(output_jsonl_text: str, mapping: dict) -> pd.DataFrame:
    out_rows = []
    for line in output_jsonl_text.splitlines():
        if not line.strip():
            continue
        obj = json.loads(line)

        if obj.get("error"):
            # Ø³Ø·Ø± ÙØ´Ù„ ÙÙŠ Ø§Ù„Ø¨Ø§ØªØ´
            continue

        resp = obj.get("response") or {}
        if resp.get("status_code") != 200:
            continue

        body = resp.get("body") or {}
        choices = body.get("choices") or []
        if not choices:
            continue

        content = choices[0].get("message", {}).get("content", "").strip()
        try:
            content_obj = json.loads(content)
        except json.JSONDecodeError:
            continue

        pred = str(content_obj.get("gender", "")).strip().lower()
        if pred not in ("male", "female", "unknown"):
            pred = "unknown"

        cid = obj.get("custom_id")
        meta = mapping.get(cid, {})
        out_rows.append({
            "original_row": meta.get("original_row", ""),
            "author.name": meta.get("name", ""),
            "author.username": meta.get("username", ""),
            "author.description": meta.get("description", ""),
            "gender": pred
        })

    return pd.DataFrame(out_rows)

# ==============================
# Ø­ÙØ¸ Ø¥Ù„Ù‰ Ø¥ÙƒØ³Ù„ + Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¨Ø³ÙŠØ·Ø©
# ==============================
def save_labeled_excel(df: pd.DataFrame, path: str):
    if df.empty:
        print("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬ Ù„Ù„Ø­ÙØ¸.")
        return
    # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
    counts = df["gender"].value_counts(dropna=False)
    stats_df = pd.DataFrame({
        "gender": counts.index,
        "count": counts.values,
        "percent_%": (counts.values / len(df) * 100).round(2)
    })
    try:
        with pd.ExcelWriter(path, engine="openpyxl") as writer:
            df.to_excel(writer, index=False, sheet_name="labeled")
            stats_df.to_excel(writer, index=False, sheet_name="stats")
        print(f"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ: {path}")
        print(f"ğŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø£Ø³Ø·Ø± Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {len(df)} (Ù…Ù† Ø§Ù„Ø³Ø·Ø± 2150 Ø¥Ù„Ù‰ 3000)")
        print(stats_df)
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­ÙØ¸: {e}")

# ==============================
# Main
# ==============================
def main():
    print("ğŸš€ Gender Batch (male/female/unknown) â€” Ø§Ù„Ø£Ø³Ø·Ø± 2150-3000 â€” GPT-4o â€” OpenAI Batch API ÙÙ‚Ø·")
    df = load_rows_2150_to_3000(INPUT_XLSX)

    # 1) Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø·Ù„Ø¨Ø§Øª + Ø§Ù„Ù…Ø§Ø¨Ù†Ø¬
    prepare_jsonl_for_batch(df, REQ_JSONL, MAP_JSONL)

    # 2) Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù ÙˆØ¥Ù†Ø´Ø§Ø¡ Batch
    file_id = upload_file_for_batch(REQ_JSONL)
    batch_id = create_batch_job(file_id, completion_window=BATCH_COMPLETION_WINDOW)

    # 3) Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ø­ØªÙ‰ Ø§Ù„Ø§ÙƒØªÙ…Ø§Ù„
    status_obj = poll_batch_until_done(batch_id, poll_interval=20)
    final_status = status_obj.get("status")
    print(f"âœ… Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©: {final_status}")
    if final_status != "completed":
        print("âŒ Ù„Ù… ÙŠÙƒØªÙ…Ù„ Ø§Ù„Ø¨Ø§ØªØ´ Ø¨Ù†Ø¬Ø§Ø­:", status_obj)
        return

    # 4) ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø®Ø§Ù…
    out_file_id = status_obj.get("output_file_id")
    if not out_file_id:
        print("âŒ Ù„Ø§ ÙŠÙˆØ¬Ø¯ output_file_id.")
        return
    out_text = download_file_content(out_file_id)
    with open(RAW_OUT, "w", encoding="utf-8") as f:
        f.write(out_text)
    print(f"ğŸ“¥ ØªÙ… Ø­ÙØ¸ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø§ØªØ´ Ø§Ù„Ø®Ø§Ù…: {RAW_OUT}")

    # 5) Ø¯Ù…Ø¬ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù…Ø¹ Ø§Ù„Ø£ØµÙ„
    mapping = load_mapping(MAP_JSONL)
    labeled_df = parse_and_merge(out_text, mapping)

    # 6) Ø­ÙØ¸ Ø¥Ù„Ù‰ Ø¥ÙƒØ³Ù„
    save_labeled_excel(labeled_df, OUT_XLSX)

if __name__ == "__main__":
    try:
        import openpyxl  # noqa: F401
    except ImportError:
        print("ğŸ“¦ ØªØ«Ø¨ÙŠØª openpyxl...")
        import sys
        !pip install openpyxl -q
        import openpyxl  # noqa: F401

    main()
